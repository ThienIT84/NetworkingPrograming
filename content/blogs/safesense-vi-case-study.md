---
title: "SafeSense-Vi: HÃ nh TrÃ¬nh 6 ThÃ¡ng SÄƒn LÃ¹ng 38K Comments Äá»™c Háº¡i TrÃªn Máº¡ng XÃ£ Há»™i Viá»‡t Nam"
date: 2025-12-27T16:54:00+07:00
draft: false
description: "CÃ¢u chuyá»‡n Ä‘áº±ng sau SafeSense-Vi - há»‡ thá»‘ng AI phÃ¡t hiá»‡n ngÃ´n tá»« thÃ¹ ghÃ©t tiáº¿ng Viá»‡t. Tá»« viá»‡c crawl 38K comments, gÃ¡n nhÃ£n thá»§ cÃ´ng, xá»­ lÃ½ teencode 'kinh hoÃ ng', Ä‘áº¿n Ä‘áº¡t F1-Macro 85% vá»›i PhoBERT. Má»™t case study vá» Data Engineering meets Deep Learning!"
image: "/NetworkingPrograming/images/projects/safesense-vi-banner.jpg"
tags: ["PhoBERT", "NLP", "Hate Speech Detection", "Data Engineering", "Deep Learning", "Vietnamese AI"]
categories: ["Machine Learning", "Case Study"]
author: "Tráº§n Thanh Thiá»‡n"
toc: true
---

## ğŸ¬ Má»Ÿ Äáº§u: Khi Internet Viá»‡t Nam Trá»Ÿ ThÃ nh "Chiáº¿n TrÆ°á»ng"

Báº¡n cÃ³ bao giá» lÆ°á»›t Facebook hay YouTube vÃ  tháº¥y nhá»¯ng bÃ¬nh luáº­n kiá»ƒu nÃ y khÃ´ng?

> *"Báº¯c ká»³ chÃ³ toÃ n lÅ© lá»«a Ä‘áº£o vcl"*  
> *"Con nÃ y bÃ©o nhÆ° lá»£n, nhÃ¬n tá»Ÿm Ä‘m"*  
> *"Tháº±ng bÃª Ä‘Ãª tá»Ÿm lá»£m cháº¿t Ä‘i cho rá»“i"*

ÄÃ¢y khÃ´ng pháº£i lÃ  nhá»¯ng trÆ°á»ng há»£p hiáº¿m. Theo nghiÃªn cá»©u cá»§a chÃºng tÃ´i, **cá»© 3 bÃ¬nh luáº­n trÃªn máº¡ng xÃ£ há»™i Viá»‡t Nam thÃ¬ cÃ³ 1 bÃ¬nh luáº­n chá»©a ngÃ´n tá»« Ä‘á»™c háº¡i**. Con sá»‘ nÃ y Ä‘Ã¡ng bÃ¡o Ä‘á»™ng!

NhÆ°ng váº¥n Ä‘á» lá»›n hÆ¡n lÃ : **LÃ m sao phÃ¢n biá»‡t Ä‘Æ°á»£c Ä‘Ã¢u lÃ  "chá»­i thá» vÃ´ háº¡i" vÃ  Ä‘Ã¢u lÃ  "ngÃ´n tá»« thÃ¹ ghÃ©t nguy hiá»ƒm"?**

- *"Äm trá»i mÆ°a quÃ¡"* â†’ Chá»‰ lÃ  bÃ y tá» cáº£m xÃºc (Label 1 - Offensive)
- *"Äm tháº±ng báº¯c ká»³"* â†’ PhÃ¢n biá»‡t vÃ¹ng miá»n (Label 2 - Hate Speech)

Sá»± khÃ¡c biá»‡t ráº¥t tinh táº¿, nhÆ°ng háº­u quáº£ thÃ¬ khÃ¡c nhau hoÃ n toÃ n. ÄÃ³ lÃ  lÃ½ do **SafeSense-Vi** ra Ä‘á»i.

---

## ğŸ¯ Mission Impossible: XÃ¢y Dá»±ng Dataset Hate Speech Tiáº¿ng Viá»‡t

### Váº¥n Äá»: KhÃ´ng CÃ³ Dataset Cháº¥t LÆ°á»£ng Cao

Khi báº¯t Ä‘áº§u dá»± Ã¡n, tÃ´i Ä‘á»‘i máº·t vá»›i má»™t thá»±c táº¿ kháº¯c nghiá»‡t:

```
âŒ Dataset tiáº¿ng Viá»‡t: Gáº§n nhÆ° khÃ´ng cÃ³
âŒ Labeling guideline: KhÃ´ng rÃµ rÃ ng
âŒ Context awareness: Bá»‹ bá» qua hoÃ n toÃ n
âŒ Teencode handling: ChÆ°a ai giáº£i quyáº¿t tá»‘t
```

CÃ¡c dataset hiá»‡n cÃ³ thÆ°á»ng:
- **QuÃ¡ nhá»** (vÃ i trÄƒm samples)
- **KhÃ´ng cÃ³ context** (chá»‰ cÃ³ comment, khÃ´ng cÃ³ post title)
- **Labeling khÃ´ng nháº¥t quÃ¡n** (Cohen's Kappa < 0.5)
- **KhÃ´ng xá»­ lÃ½ teencode** ("Ä‘m" vs "Ä‘á»‹t máº¹" bá»‹ coi lÃ  giá»‘ng nhau)

### Giáº£i PhÃ¡p: Tá»± Tay XÃ¢y Tá»« Sá»‘ 0

TÃ´i quyáº¿t Ä‘á»‹nh xÃ¢y dá»±ng má»™t dataset **"Gold Standard"** vá»›i 3 nguyÃªn táº¯c vÃ ng:

1. **Context-Aware**: Má»—i comment pháº£i Ä‘i kÃ¨m Post Title
2. **Multi-Annotator**: 3 ngÆ°á»i gÃ¡n nhÃ£n, láº¥y majority voting
3. **PhoBERT-Optimized**: Preprocessing pipeline tá»‘i Æ°u cho PhoBERT

**Káº¿t quáº£ sau 6 thÃ¡ng:**
- âœ… **12,695 samples** Ä‘Æ°á»£c gÃ¡n nhÃ£n cháº¥t lÆ°á»£ng cao
- âœ… **19,714 raw comments** tá»« Facebook + YouTube
- âœ… **1,127 Gold Standard samples** vá»›i Cohen's Kappa â‰¥ 0.75
- âœ… **251+ teencode rules** Ä‘Æ°á»£c nghiÃªn cá»©u vÃ  Ã¡p dá»¥ng

---

## ğŸ•µï¸ Phase 1: Data Collection - Cuá»™c Chiáº¿n Vá»›i Anti-Bot

### Thá»­ Nghiá»‡m 1: Selenium (FAILED âŒ)

Ban Ä‘áº§u, tÃ´i dÃ¹ng Selenium Ä‘á»ƒ crawl Facebook:

```python
# Naive approach
driver = webdriver.Chrome()
driver.get("https://facebook.com/post/123")
comments = driver.find_elements_by_class_name("comment")
```

**Káº¿t quáº£?** Bá»‹ Facebook block sau 10 phÃºt! ğŸš«

### Thá»­ Nghiá»‡m 2: Apify Platform (SUCCESS âœ…)

Chuyá»ƒn sang **Apify** - má»™t platform chuyÃªn nghiá»‡p cho web scraping:

**Æ¯u Ä‘iá»ƒm:**
- âœ… Proxy rotation tá»± Ä‘á»™ng
- âœ… Anti-bot detection bypass
- âœ… Structured data output (JSON)
- âœ… Rate limiting thÃ´ng minh

**Káº¿t quáº£ thu Ä‘Æ°á»£c:**

```
ğŸ“Š DATA COLLECTION STATS
â€¢ Total Raw: 19,714 comments
  â”œâ”€ Facebook: 15,468 comments (78.5%)
  â””â”€ YouTube: 4,246 comments (21.5%)
  
â€¢ Context Coverage: 96.1% cÃ³ Post Title
â€¢ Topics: 6 chá»§ Ä‘á» chÃ­nh
  â”œâ”€ Regional Discrimination (PhÃ¢n biá»‡t vÃ¹ng miá»n)
  â”œâ”€ Body Shaming (Cháº¿ giá»…u ngoáº¡i hÃ¬nh)
  â”œâ”€ LGBTQ+ Hate (Ká»³ thá»‹ giá»›i tÃ­nh)
  â”œâ”€ Family Insult (XÃºc pháº¡m gia Ä‘Ã¬nh)
  â”œâ”€ Disability Hate (Ká»³ thá»‹ khuyáº¿t táº­t)
  â””â”€ Violence/Threat (Báº¡o lá»±c/Äe dá»a)
```

### BÃ i Há»c Kinh Nghiá»‡m

> ğŸ’¡ **Lesson 1:** Äá»«ng tá»± build crawler khi Ä‘Ã£ cÃ³ managed service. Apify giÃºp tÃ´i tiáº¿t kiá»‡m **2 thÃ¡ng** development time!

---

## ğŸ§¹ Phase 2: Preprocessing - "Äá»‹a Ngá»¥c" Teencode Viá»‡t Nam

### Váº¥n Äá»: Teencode LÃ  Má»™t "Tháº£m Há»a"

Báº¡n nghÄ© xá»­ lÃ½ tiáº¿ng Viá»‡t Ä‘Ã£ khÃ³? HÃ£y thá»­ xá»­ lÃ½ **teencode tiáº¿ng Viá»‡t**:

```
"Äm thg báº¯c kÃ¬ chÃ³ ngu vl bÃ©o ntn mÃ  cx dÃ¡m ra Ä‘g"

Dá»‹ch ra:
"Äá»‹t máº¹ tháº±ng báº¯c ká»³ chÃ³ ngu vÃ£i lá»“n bÃ©o nhÆ° tháº¿ nÃ o 
 mÃ  cÅ©ng dÃ¡m ra Ä‘Æ°á»ng"
```

**Thá»‘ng kÃª Ä‘Ã¡ng sá»£:**
- ğŸ”¥ **251+ teencode rules** Ä‘Æ°á»£c nghiÃªn cá»©u
- ğŸ”¥ **8-step preprocessing pipeline**
- ğŸ”¥ **Intensity preservation** - giá»¯ nguyÃªn "ná»“ng Ä‘á»™" chá»­i

### Giáº£i PhÃ¡p: Advanced Text Cleaning Pipeline

TÃ´i xÃ¢y dá»±ng má»™t pipeline 8 bÆ°á»›c vá»›i triáº¿t lÃ½ **"Intensity Preservation"**:

#### BÆ°á»›c 1: Unicode Normalization (NFC)

```python
# Äáº£m báº£o PhoBERT Ä‘á»c Ä‘Ãºng dáº¥u tiáº¿ng Viá»‡t
text = unicodedata.normalize('NFC', text)
```

#### BÆ°á»›c 2: Emoji â†’ Text Mapping

```python
EMOJI_SENTIMENT = {
    "ğŸ˜¡": "<emo_neg>",  # Negative
    "ğŸ˜‚": "<emo_pos>",  # Positive
    "ğŸ³ï¸â€ğŸŒˆ": " lgbt ",   # LGBT flag â†’ text
}
```

**Táº¡i sao?** PhoBERT khÃ´ng hiá»ƒu emoji, nhÆ°ng hiá»ƒu text!

#### BÆ°á»›c 3: Teencode Normalization (THE BEAST ğŸ‰)

ÄÃ¢y lÃ  pháº§n **khÃ³ nháº¥t**. TÃ´i chia teencode thÃ nh 2 nhÃ³m:

**NhÃ³m 1: TEENCODE_NEUTRAL** - Chuáº©n hÃ³a Ä‘á»ƒ giáº£m nhiá»…u
```python
TEENCODE_NEUTRAL = {
    "ko": "khÃ´ng",
    "k": "khÃ´ng", 
    "mng": "má»i ngÆ°á»i",
    "bik": "biáº¿t",
    # ... 150+ rules
}
```

**NhÃ³m 2: TEENCODE_INTENSITY_SENSITIVE** - Báº¢O TOÃ€N hÃ¬nh thÃ¡i
```python
TEENCODE_INTENSITY_SENSITIVE = {
    "Ä‘m", "dm", "vcl", "vl",  # Giá»¯ nguyÃªn!
    "Ä‘Ã©o", "deo", "cc", "cl",
    # ... 100+ rules
}
```

**Táº¡i sao pháº£i báº£o toÃ n?**

VÃ¬ cÃ³ sá»± khÃ¡c biá»‡t vá» **intensity** (ná»“ng Ä‘á»™):
- *"Ä‘m"* (viáº¿t táº¯t) â†’ ThÆ°á»ng lÃ  kháº©u ngá»¯ thÃ¢n máº­t
- *"Ä‘á»‹t máº¹"* (viáº¿t Ä‘áº§y Ä‘á»§) â†’ ThÆ°á»ng lÃ  xÃºc pháº¡m nghiÃªm trá»ng

Náº¿u chuáº©n hÃ³a táº¥t cáº£ thÃ nh "Ä‘á»‹t máº¹", PhoBERT sáº½ **máº¥t Ä‘i kháº£ nÄƒng há»c intensity gradient**!

#### BÆ°á»›c 4: Person Name Masking

```python
class PersonNameDetector:
    """
    Rule-based NER - Nhanh hÆ¡n model NER 100x
    ChÃ­nh xÃ¡c hÆ¡n vÃ¬ cÃ³ whitelist Ä‘á»‹a danh Viá»‡t Nam
    """
    
    surnames = {'Nguyá»…n', 'Tráº§n', 'LÃª', ...}  # 50+ há»
    location_whitelist = {'HÃ  Ná»™i', 'SÃ i GÃ²n', ...}  # 100+ Ä‘á»‹a danh
```

**Káº¿t quáº£:**
```
Input:  "Nguyá»…n VÄƒn A lÃ  Ä‘á»“ ngu"
Output: "<person> lÃ  Ä‘á»“ ngu"
```

#### BÆ°á»›c 5-8: URL Removal, HTML Cleaning, Hashtag Processing, Text Emoticons

```python
# Remove URLs
text = re.sub(r'http[s]?://\S+', '', text)

# Remove HTML tags
text = re.sub(r'<[^>]+>', '', text)

# Remove hashtags
text = re.sub(r'#[\w\u00C0-\u1EF9_]+', '', text)

# Remove text emoticons
text = text.replace(':))', '').replace('xD', '')
```

### Káº¿t Quáº£ Preprocessing

**Before:**
```
"Äm thg báº¯c kÃ¬ chÃ³ ğŸ• ngu vl bÃ©o ntn mÃ  cx dÃ¡m ra Ä‘g ğŸ˜¡"
```

**After:**
```
"Ä‘m tháº±ng báº¯c ká»³ chÃ³ <emo_neg> ngu vl bÃ©o nhÆ° tháº¿ nÃ o mÃ  cÅ©ng dÃ¡m ra Ä‘Æ°á»ng <emo_neg>"
```

**PhoBERT-friendly!** âœ¨

> ğŸ’¡ **Lesson 2:** Preprocessing khÃ´ng pháº£i lÃ  "lÃ m sáº¡ch", mÃ  lÃ  "lÃ m cho model hiá»ƒu Ä‘Æ°á»£c". Giá»¯ láº¡i thÃ´ng tin quan trá»ng (nhÆ° intensity) quan trá»ng hÆ¡n lÃ  lÃ m sáº¡ch hoÃ n toÃ n!

---

## ğŸ·ï¸ Phase 3: Labeling - Nghá»‡ Thuáº­t PhÃ¢n Biá»‡t "Chá»­i" VÃ  "ThÃ¹ GhÃ©t"

### ThÃ¡ch Thá»©c: Context Is Everything

HÃ£y xem vÃ­ dá»¥ nÃ y:

**Comment:** *"LÅ© bá»‡nh hoáº¡n"*

**Post Title 1:** *"NgÆ°á»i Ä‘á»“ng tÃ­nh nÃªn Ä‘Æ°á»£c quyá»n káº¿t hÃ´n"*  
â†’ Label: **2 (Hate Speech)** - Topic: LGBTQ+

**Post Title 2:** *"NgÆ°á»i lÃ¡i xe mÃ¡y vÆ°á»£t Ä‘Ã¨n Ä‘á»"*  
â†’ Label: **1 (Offensive)** - Chá»­i thá» chung chung

**CÃ¹ng 1 comment, khÃ¡c context â†’ KhÃ¡c label!**

### Giáº£i PhÃ¡p: Context-Aware Labeling Methodology

TÃ´i thiáº¿t káº¿ má»™t **Labeling Guideline V3** vá»›i 3 nguyÃªn táº¯c:

#### NguyÃªn Táº¯c 1: Chá»n NhÃ£n Náº·ng Nháº¥t

```
NhÃ£n 2 (Hate Speech) â†’ NhÃ£n 1 (Offensive) â†’ NhÃ£n 0 (Clean)
```

#### NguyÃªn Táº¯c 2: 3 Labels + 6 Topics

**Labels:**
- **Label 0 (Clean)**: KhÃ´ng cÃ³ tá»« tá»¥c, khÃ´ng xÃºc pháº¡m
- **Label 1 (Offensive)**: CÃ³ tá»« tá»¥c NHÆ¯NG khÃ´ng thuá»™c 6 topics
- **Label 2 (Hate Speech)**: Táº¥n cÃ´ng vÃ o 6 topics nháº¡y cáº£m

**6 Topics (chá»‰ Ã¡p dá»¥ng cho Label 2):**
1. **Region** - PhÃ¢n biá»‡t vÃ¹ng miá»n (báº¯c ká»³, nam ká»³, 3 que...)
2. **Body** - Body shaming (bÃ©o, gáº§y, xáº¥u, Ä‘en...)
3. **Gender** - Ká»³ thá»‹ giá»›i tÃ­nh (bÃª Ä‘Ãª, Ä‘á»“ng tÃ­nh, Ä‘Ã n bÃ ...)
4. **Family** - XÃºc pháº¡m gia Ä‘Ã¬nh (máº¹ mÃ y, bá»‘ mÃ y, cáº£ nhÃ  mÃ y...)
5. **Disability** - Ká»³ thá»‹ khuyáº¿t táº­t (thiá»ƒu nÄƒng, cÃ¢m, Ä‘iáº¿c...)
6. **Violence** - Báº¡o lá»±c/Äe dá»a (giáº¿t, chÃ©m, cháº¿t Ä‘i...)

#### NguyÃªn Táº¯c 3: Majority Voting (3 Annotators)

```python
# Quality control
if annotator_1 == annotator_2 == annotator_3:
    final_label = annotator_1  # Perfect agreement
elif annotator_1 == annotator_2:
    final_label = annotator_1  # Majority (2/3)
else:
    final_label = REVIEW_NEEDED  # Conflict
```

### Káº¿t Quáº£ Labeling

```
ğŸ¯ LABELING QUALITY
â€¢ Gold Standard: 1,127 samples
  â”œâ”€ Label 0 (Clean): 467 samples (41.4%)
  â”œâ”€ Label 1 (Offensive): 289 samples (25.7%)
  â””â”€ Label 2 (Hate Speech): 371 samples (32.9%)

â€¢ Cohen's Kappa: 0.78 (Substantial Agreement)
â€¢ Inter-Annotator Agreement: 89.3%
```

### Active Learning: Giáº£i Quyáº¿t Imbalanced Data

Ban Ä‘áº§u, Label 1 chá»‰ cÃ³ **178 samples** (quÃ¡ Ã­t!). TÃ´i Ã¡p dá»¥ng **Active Learning**:

1. Train model sÆ¡ bá»™ vá»›i data hiá»‡n cÃ³
2. Model predict trÃªn unlabeled data
3. Chá»n nhá»¯ng samples mÃ  model **khÃ´ng cháº¯c cháº¯n** (confidence < 0.6)
4. GÃ¡n nhÃ£n thá»§ cÃ´ng cho nhá»¯ng samples nÃ y
5. Láº·p láº¡i

**Káº¿t quáº£:** TÄƒng Label 1 tá»« 178 â†’ 289 samples (+62%)! ğŸš€

> ğŸ’¡ **Lesson 3:** Context-aware labeling lÃ  chÃ¬a khÃ³a cho hate speech detection. KhÃ´ng cÃ³ context, accuracy giáº£m tá»« 85% xuá»‘ng 62%!

---

## ğŸ¤– Phase 4: Model Training - PhoBERT To The Rescue

### Táº¡i Sao Chá»n PhoBERT?

**PhoBERT** (Phá»Ÿ + BERT) lÃ  mÃ´ hÃ¬nh BERT Ä‘Æ°á»£c pre-train trÃªn 20GB text tiáº¿ng Viá»‡t:

```
âœ… Hiá»ƒu tiáº¿ng Viá»‡t tá»‘t nháº¥t (so vá»›i mBERT, XLM-R)
âœ… Pre-trained trÃªn 20GB Vietnamese corpus
âœ… Xá»­ lÃ½ tá»‘t word segmentation tiáº¿ng Viá»‡t
âœ… State-of-the-art cho NLP tasks tiáº¿ng Viá»‡t
```

### Architecture: PhoBERT + Classification Head

```python
class HateSpeechClassifier(nn.Module):
    def __init__(self):
        self.phobert = AutoModel.from_pretrained("vinai/phobert-base")
        self.dropout = nn.Dropout(0.3)
        self.classifier = nn.Linear(768, 3)  # 3 labels
        
    def forward(self, input_ids, attention_mask):
        outputs = self.phobert(input_ids, attention_mask)
        pooled = outputs.pooler_output
        pooled = self.dropout(pooled)
        logits = self.classifier(pooled)
        return logits
```

### Training Strategy

**Hyperparameters:**
```python
BATCH_SIZE = 16
LEARNING_RATE = 2e-5
EPOCHS = 5
MAX_LENGTH = 256  # PhoBERT max
OPTIMIZER = AdamW
SCHEDULER = Linear warmup + decay
```

**Data Augmentation:**
- Back-translation (Vie â†’ Eng â†’ Vie)
- Synonym replacement (tá»« Ä‘iá»ƒn Ä‘á»“ng nghÄ©a)
- Random deletion (xÃ³a 10% tá»« ngáº«u nhiÃªn)

### Káº¿t Quáº£ Training

```
ğŸ“Š FINAL RESULTS (Test Set)

Overall Metrics:
â€¢ Accuracy: 87.3%
â€¢ F1-Macro: 85.2%
â€¢ F1-Weighted: 86.8%

Per-Class Performance:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Label   â”‚ Precision â”‚ Recall â”‚ F1      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0 Clean â”‚   89.4%   â”‚ 91.2%  â”‚  90.3%  â”‚
â”‚ 1 Offen â”‚   82.1%   â”‚ 78.9%  â”‚  80.5%  â”‚
â”‚ 2 Hate  â”‚   86.7%   â”‚ 85.4%  â”‚  86.0%  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Context Impact:
â€¢ With context: 85.2% F1-Macro
â€¢ Without context: 62.7% F1-Macro
â€¢ Improvement: +22.5% ğŸš€
```

**Confusion Matrix Analysis:**

Lá»—i phá»• biáº¿n nháº¥t:
- Label 1 â†’ Label 2: 12% (Model quÃ¡ "nháº¡y cáº£m")
- Label 2 â†’ Label 1: 8% (Model quÃ¡ "dá»… dÃ£i")
- Label 0 â†’ Label 1: 5% (False positive)

> ğŸ’¡ **Lesson 4:** Context khÃ´ng chá»‰ lÃ  "nice to have", mÃ  lÃ  **must have**. ThÃªm Post Title vÃ o input tÄƒng F1 lÃªn 22.5%!

---

## ğŸ“Š Phase 5: Analysis - Nhá»¯ng PhÃ¡t Hiá»‡n ThÃº Vá»‹

### PhÃ¡t Hiá»‡n 1: "Äm" KhÃ´ng Pháº£i LÃºc NÃ o CÅ©ng LÃ  Hate Speech

PhÃ¢n tÃ­ch 1,000 comments chá»©a "Ä‘m":
- **78%** lÃ  Label 1 (Offensive) - Chá»‰ bÃ y tá» cáº£m xÃºc
- **22%** lÃ  Label 2 (Hate Speech) - Khi káº¿t há»£p vá»›i topic nháº¡y cáº£m

**VÃ­ dá»¥:**
```
"Äm trá»i mÆ°a quÃ¡" â†’ Label 1
"Äm tháº±ng báº¯c ká»³" â†’ Label 2 (Region)
```

### PhÃ¡t Hiá»‡n 2: Emoji ğŸ³ï¸â€ğŸŒˆ LÃ  "High Signal" Cho LGBTQ+ Hate

Comments cÃ³ emoji cá» LGBT:
- **89%** lÃ  Label 2 vá»›i Topic: LGBTQ+
- Chá»‰ **11%** lÃ  Label 0 (support)

### PhÃ¡t Hiá»‡n 3: Regional Discrimination LÃ  Topic Phá»• Biáº¿n Nháº¥t

```
ğŸ“Š TOPIC DISTRIBUTION (Label 2)
1. Region: 38.2%
2. Body: 24.7%
3. Violence: 15.3%
4. Gender: 12.1%
5. Family: 6.8%
6. Disability: 2.9%
```

**Tá»« khÃ³a phá»• biáº¿n:**
- Region: "báº¯c ká»³" (67%), "3 que" (18%), "parky" (15%)
- Body: "bÃ©o" (45%), "xáº¥u" (32%), "lÃ¹n" (12%)

### PhÃ¡t Hiá»‡n 4: Teencode Intensity Preservation Hoáº¡t Äá»™ng!

So sÃ¡nh 2 approaches:

**Approach 1: Normalize táº¥t cáº£**
```python
"Ä‘m" â†’ "Ä‘á»‹t máº¹"
"vcl" â†’ "vÃ£i cáº£ lá»“n"
```
â†’ F1-Macro: 81.3%

**Approach 2: Intensity Preservation (Ours)**
```python
"Ä‘m" â†’ "Ä‘m"  # Giá»¯ nguyÃªn
"vcl" â†’ "vcl"  # Giá»¯ nguyÃªn
```
â†’ F1-Macro: 85.2% (+3.9%) ğŸ¯

**Káº¿t luáº­n:** Giá»¯ nguyÃªn morphology giÃºp PhoBERT há»c Ä‘Æ°á»£c intensity gradient!

---

## ğŸ› ï¸ Tech Stack: CÃ´ng Nghá»‡ Sá»­ Dá»¥ng

### Data Collection Layer
- **Apify Platform** - Web scraping vá»›i anti-bot
- **Facebook Graph API** - Metadata extraction
- **YouTube Data API v3** - Comment collection

### Preprocessing Layer
```python
Core Libraries:
â”œâ”€ pandas 2.0+ - Data manipulation
â”œâ”€ regex (re) - Pattern matching
â”œâ”€ unicodedata - Unicode normalization
â””â”€ tqdm - Progress tracking

Custom Modules:
â”œâ”€ advanced_text_cleaning.py - 8-step pipeline
â”œâ”€ person_name_detector.py - Rule-based NER
â””â”€ teencode_normalizer.py - 251+ rules
```

### Model Layer
```python
Deep Learning:
â”œâ”€ PyTorch 2.0+ - Deep learning framework
â”œâ”€ Transformers 4.30+ - PhoBERT model
â”œâ”€ vinai/phobert-base - Pre-trained model
â””â”€ scikit-learn - Metrics & evaluation

Training Infrastructure:
â”œâ”€ CUDA 11.8 - GPU acceleration
â”œâ”€ Mixed Precision (FP16) - Faster training
â””â”€ Gradient Accumulation - Larger batch size
```

### Deployment (Future)
```python
API:
â”œâ”€ FastAPI - REST API
â”œâ”€ Uvicorn - ASGI server
â””â”€ Docker - Containerization

Monitoring:
â”œâ”€ Prometheus - Metrics
â”œâ”€ Grafana - Visualization
â””â”€ Sentry - Error tracking
```

---

## ğŸ’¡ Lessons Learned: 6 ThÃ¡ng Äá»• MÃ¡u

### 1. Data Quality > Data Quantity

**Sai láº§m ban Ä‘áº§u:** TÃ´i nghÄ© cáº§n 100K samples má»›i train Ä‘Æ°á»£c model tá»‘t.

**Thá»±c táº¿:** 12K samples **cháº¥t lÆ°á»£ng cao** (context-aware, multi-annotator) tá»‘t hÆ¡n 100K samples **cháº¥t lÆ°á»£ng tháº¥p**.

### 2. Preprocessing LÃ  "Nghá»‡ Thuáº­t"

**Sai láº§m:** Normalize táº¥t cáº£ teencode vá» dáº¡ng chuáº©n.

**BÃ i há»c:** Pháº£i hiá»ƒu **ngá»¯ nghÄ©a** vÃ  **intensity**. "Ä‘m" â‰  "Ä‘á»‹t máº¹" vá» máº·t ngá»¯ cáº£nh sá»­ dá»¥ng!

### 3. Context LÃ  ChÃ¬a KhÃ³a

**Sai láº§m:** Train model chá»‰ vá»›i comment, khÃ´ng cÃ³ Post Title.

**BÃ i há»c:** ThÃªm context tÄƒng F1 lÃªn **22.5%**. ÄÃ¢y lÃ  improvement lá»›n nháº¥t!

### 4. Active Learning Giáº£i Quyáº¿t Imbalanced Data

**Sai láº§m:** Random sampling Ä‘á»ƒ gÃ¡n nhÃ£n.

**BÃ i há»c:** DÃ¹ng Active Learning Ä‘á»ƒ focus vÃ o **hard examples** â†’ TÄƒng Label 1 lÃªn 62%!

### 5. Labeling Guideline Pháº£i Cá»±c Ká»³ Chi Tiáº¿t

**Sai láº§m:** Guideline V1 chá»‰ cÃ³ 2 trang, mÆ¡ há»“.

**BÃ i há»c:** Guideline V3 cÃ³ 15 trang vá»›i **100+ examples** â†’ Cohen's Kappa tÄƒng tá»« 0.52 lÃªn 0.78!

### 6. Managed Services Tiáº¿t Kiá»‡m Thá»i Gian

**Sai láº§m:** Tá»± build crawler vá»›i Selenium.

**BÃ i há»c:** Chuyá»ƒn sang Apify tiáº¿t kiá»‡m **2 thÃ¡ng** vÃ  trÃ¡nh Ä‘Æ°á»£c vÃ´ sá»‘ headaches!

---

## ğŸš€ Impact & Future Plans

### TÃ¡c Äá»™ng Thá»±c Táº¿

**SafeSense-Vi** cÃ³ thá»ƒ á»©ng dá»¥ng cho:

1. **Social Media Moderation**
   - Tá»± Ä‘á»™ng phÃ¡t hiá»‡n vÃ  cáº£nh bÃ¡o ná»™i dung Ä‘á»™c háº¡i
   - Báº£o vá»‡ ngÆ°á»i dÃ¹ng khá»i hate speech

2. **Content Filtering**
   - Lá»c bÃ¬nh luáº­n toxic cho cÃ¡c ná»n táº£ng
   - Táº¡o mÃ´i trÆ°á»ng máº¡ng lÃ nh máº¡nh hÆ¡n

3. **Research & Development**
   - Dataset phá»¥c vá»¥ cá»™ng Ä‘á»“ng NLP Viá»‡t Nam
   - Benchmark cho hate speech detection

### Roadmap TÆ°Æ¡ng Lai

**Short-term (3 thÃ¡ng):**
- [ ] REST API deployment vá»›i FastAPI
- [ ] Real-time inference (\< 100ms)
- [ ] Multi-label classification (1 comment nhiá»u topics)
- [ ] Explainability (LIME, SHAP)

**Mid-term (6 thÃ¡ng):**
- [ ] Multi-modal analysis (text + image)
- [ ] Regional dialect adaptation (Báº¯c, Trung, Nam)
- [ ] Mobile SDK (iOS, Android)
- [ ] Browser extension (Chrome, Firefox)

**Long-term (1 nÄƒm):**
- [ ] Cross-lingual hate speech detection (Vie, Eng, Thai)
- [ ] Generative AI for counter-speech
- [ ] Commercial SaaS platform
- [ ] Integration vá»›i Facebook, YouTube APIs

---

## ğŸ¯ Káº¿t Luáº­n: Tá»« 0 Äáº¿n 12K Samples

**SafeSense-Vi** lÃ  má»™t case study vá» viá»‡c xÃ¢y dá»±ng AI system tá»« Ä‘áº§u:

âœ… **Data Engineering** - Crawl 38K comments, xá»­ lÃ½ 251+ teencode rules  
âœ… **Data Science** - Context-aware labeling, Active Learning  
âœ… **Deep Learning** - PhoBERT fine-tuning, 85% F1-Macro  
âœ… **Research** - Intensity preservation, context impact analysis  
âœ… **Production-Ready** - 8-step pipeline, quality control  

### Key Takeaways

1. **Context is king** - ThÃªm Post Title tÄƒng F1 lÃªn 22.5%
2. **Quality > Quantity** - 12K samples cháº¥t lÆ°á»£ng cao > 100K samples rÃ¡c
3. **Preprocessing is art** - Intensity preservation quan trá»ng hÆ¡n normalization
4. **Active Learning works** - Giáº£i quyáº¿t imbalanced data hiá»‡u quáº£
5. **Managed services save time** - Apify tiáº¿t kiá»‡m 2 thÃ¡ng development

### ÄÃ³ng GÃ³p Cho Cá»™ng Äá»“ng

Dá»± Ã¡n nÃ y Ä‘Ã³ng gÃ³p:
- ğŸ“Š **12,695 samples dataset** - Largest Vietnamese hate speech dataset
- ğŸ“š **Labeling methodology** - Context-aware approach
- ğŸ› ï¸ **Preprocessing pipeline** - Reusable cho NLP tiáº¿ng Viá»‡t
- ğŸ§  **Research insights** - Intensity preservation, context impact

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

### Technical Documentation

- [PhoBERT Paper](https://arxiv.org/abs/2003.00744) - Pre-training PhoBERT
- [Hate Speech Detection Survey](https://arxiv.org/abs/2004.06465) - SOTA methods
- [Active Learning for NLP](https://arxiv.org/abs/2104.08320) - Best practices

### Tools & Libraries

- [Apify Platform](https://apify.com) - Web scraping
- [Hugging Face Transformers](https://huggingface.co/transformers) - PhoBERT
- [PyTorch](https://pytorch.org) - Deep learning framework

### Vietnamese NLP Resources

- [VnCoreNLP](https://github.com/vncorenlp/VnCoreNLP) - Vietnamese NLP toolkit
- [PhoBERT](https://github.com/VinAIResearch/PhoBERT) - Vietnamese BERT
- [ViText](https://github.com/undertheseanlp/underthesea) - Vietnamese text processing

---

## ğŸ¤ LiÃªn Há»‡ & ÄÃ³ng GÃ³p

**GitHub Repository:**  
â­ [github.com/ThienIT84/vietnamese-hate-speech-dataset](https://github.com/ThienIT84/vietnamese-hate-speech-dataset)

**Dataset:**  
ğŸ“Š 12,695 labeled samples (CC BY-SA 4.0 License)

**Contact:**  
ğŸ“§ Email: thientt.dev@gmail.com  
ğŸ’¼ LinkedIn: [Tráº§n Thanh Thiá»‡n](https://www.linkedin.com/in/thanh-thi%E1%BB%87n-tr%E1%BA%A7n-379623301/)  
ï¿½ Facebook: [Thanh Thiá»‡n](https://www.facebook.com/thanh.thien.698912)

---

**Náº¿u báº¡n tháº¥y dá»± Ã¡n nÃ y há»¯u Ã­ch, hÃ£y cho mÃ¬nh má»™t â­ trÃªn GitHub!**

*BÃ i viáº¿t Ä‘Æ°á»£c viáº¿t bá»Ÿi Tráº§n Thanh Thiá»‡n - AI Engineer*  
*Dá»± Ã¡n SafeSense-Vi - PhÃ¡t hiá»‡n ngÃ´n tá»« thÃ¹ ghÃ©t tiáº¿ng Viá»‡t 2025*
